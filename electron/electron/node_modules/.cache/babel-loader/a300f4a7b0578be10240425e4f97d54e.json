{"ast":null,"code":"// vim: ts=4:sw=4:expandtab\n\n/*\n * jobQueue manages multiple queues indexed by device to serialize\n * session io ops on the database.\n */\n'use strict';\n\nvar _regeneratorRuntime = require(\"/Users/garybutton/Personal/iron/priv/iron/electron/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\");\n\nvar _asyncToGenerator = require(\"/Users/garybutton/Personal/iron/priv/iron/electron/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/asyncToGenerator\");\n\nvar _queueAsyncBuckets = new Map();\n\nvar _gcLimit = 10000;\n\nfunction _asyncQueueExecutor(_x, _x2) {\n  return _asyncQueueExecutor2.apply(this, arguments);\n}\n\nfunction _asyncQueueExecutor2() {\n  _asyncQueueExecutor2 = _asyncToGenerator(\n  /*#__PURE__*/\n  _regeneratorRuntime.mark(function _callee(queue, cleanup) {\n    var offt, limit, i, job;\n    return _regeneratorRuntime.wrap(function _callee$(_context) {\n      while (1) {\n        switch (_context.prev = _context.next) {\n          case 0:\n            offt = 0;\n\n          case 1:\n            if (!true) {\n              _context.next = 27;\n              break;\n            }\n\n            limit = Math.min(queue.length, _gcLimit); // Break up thundering hurds for GC duty.\n\n            i = offt;\n\n          case 4:\n            if (!(i < limit)) {\n              _context.next = 20;\n              break;\n            }\n\n            job = queue[i];\n            _context.prev = 6;\n            _context.t0 = job;\n            _context.next = 10;\n            return job.awaitable();\n\n          case 10:\n            _context.t1 = _context.sent;\n\n            _context.t0.resolve.call(_context.t0, _context.t1);\n\n            _context.next = 17;\n            break;\n\n          case 14:\n            _context.prev = 14;\n            _context.t2 = _context[\"catch\"](6);\n            job.reject(_context.t2);\n\n          case 17:\n            i++;\n            _context.next = 4;\n            break;\n\n          case 20:\n            if (!(limit < queue.length)) {\n              _context.next = 24;\n              break;\n            }\n\n            /* Perform lazy GC of queue for faster iteration. */\n            if (limit >= _gcLimit) {\n              queue.splice(0, limit);\n              offt = 0;\n            } else {\n              offt = limit;\n            }\n\n            _context.next = 25;\n            break;\n\n          case 24:\n            return _context.abrupt(\"break\", 27);\n\n          case 25:\n            _context.next = 1;\n            break;\n\n          case 27:\n            cleanup();\n\n          case 28:\n          case \"end\":\n            return _context.stop();\n        }\n      }\n    }, _callee, this, [[6, 14]]);\n  }));\n  return _asyncQueueExecutor2.apply(this, arguments);\n}\n\nmodule.exports = function (bucket, awaitable) {\n  /* Run the async awaitable only when all other async calls registered\n   * here have completed (or thrown).  The bucket argument is a hashable\n   * key representing the task queue to use. */\n  if (!awaitable.name) {\n    // Make debuging easier by adding a name to this function.\n    Object.defineProperty(awaitable, 'name', {\n      writable: true\n    });\n\n    if (typeof bucket === 'string') {\n      awaitable.name = bucket;\n    } else {\n      console.warn(\"Unhandled bucket type (for naming):\", typeof bucket, bucket);\n    }\n  }\n\n  var inactive;\n\n  if (!_queueAsyncBuckets.has(bucket)) {\n    _queueAsyncBuckets.set(bucket, []);\n\n    inactive = true;\n  }\n\n  var queue = _queueAsyncBuckets.get(bucket);\n\n  var job = new Promise(function (resolve, reject) {\n    return queue.push({\n      awaitable: awaitable,\n      resolve: resolve,\n      reject: reject\n    });\n  });\n\n  if (inactive) {\n    /* An executor is not currently active; Start one now. */\n    _asyncQueueExecutor(queue, function () {\n      return _queueAsyncBuckets.delete(bucket);\n    });\n  }\n\n  return job;\n};","map":null,"metadata":{},"sourceType":"script"}